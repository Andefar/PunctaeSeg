{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac86d51",
   "metadata": {},
   "source": [
    "# Compile the dataset for training and validation\n",
    "Load the image (flou and aflou channels) and the corresponding vessel/punctae masks.\n",
    "This notebook is used to compiled both the vessel and punctae dataset using the same splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322eab79",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f863f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "from os import walk, makedirs\n",
    "from os.path import join, exists, basename, splitext\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "from tqdm import tqdm\n",
    "from segmentation_models.metrics import f1_score, iou_score\n",
    "from skimage import filters\n",
    "import os\n",
    "from os import walk, makedirs, listdir\n",
    "from os.path import join, exists, expanduser\n",
    "import pandas as pd\n",
    "import re\n",
    "import xarray as xr\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from sklearn.cluster import KMeans\n",
    "from glob import glob "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bcab88",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93cc5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'auto_fluo_data_vessel'\n",
    "#data_dir = 'auto_fluo_data_punctae'\n",
    "validation_fraction = 0.15\n",
    "random_seed = 42\n",
    "np.random_seed(random_seed) # make sure to use the same split for vessel/punctae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403368f",
   "metadata": {},
   "source": [
    "Locate the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b683260",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(join(data_dir, '*'))\n",
    "ids = np.unique(['_'.join(basename(f).split('_')[:-1]) for f in files])\n",
    "img_pairs = {}\n",
    "for img_id in ids:\n",
    "    pair = {\n",
    "        'X1': join(data_dir,img_id + '_fluo.nc'),\n",
    "        'X2': join(data_dir,img_id + '_afluo.nc'),\n",
    "        'y':  join(data_dir,img_id + '_mask.nc')\n",
    "    }\n",
    "    img_pairs[img_id] = pair\n",
    "    \n",
    "    assert exists(pair['X1'])\n",
    "    assert exists(pair['X2'])\n",
    "    assert exists(pair['y'])\n",
    "print('ROIs found =',len(img_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c59a7f",
   "metadata": {},
   "source": [
    "## Function for loading and processing the images\n",
    "Pad to largest size and standardize pixel intensities to range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235fed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_masks(data_paths_map, target_resolution=0.12435661944309118, max_size=(576, 608), min_vals={'X1': 1.3632197, 'X2': -1.7582703}, effective_ranges={'X1': (0, 3950), 'X2': (0, 1785)}):\n",
    "    \n",
    "    X1, X2, y = [], [], []\n",
    "\n",
    "    for i, (img_id, data_map) in enumerate(data_paths_map.items()):\n",
    "        assert exists(data_map['X1']) and exists(data_map['X2']) and exists(data_map['y']), 'Data did not exist.'\n",
    "\n",
    "        data_X1 = xr.open_dataarray(data_map['X1'])\n",
    "        data_X2 = xr.open_dataarray(data_map['X2'])\n",
    "        data_y = xr.open_dataarray(data_map['y'])\n",
    "        \n",
    "        img_X1 = data_X1.data\n",
    "        img_X2 = data_X2.data\n",
    "        msk_y = data_y.data       \n",
    "        \n",
    "        X1_res = (data_X1.x.diff('x')[0].item(), data_X1.y.diff('y')[0].item())\n",
    "        X2_res = (data_X2.x.diff('x')[0].item(), data_X2.y.diff('y')[0].item())\n",
    "        y_res = (data_y.x.diff('x')[0].item(), data_y.y.diff('y')[0].item())\n",
    "\n",
    "        assert img_X1.shape == img_X2.shape and img_X1.shape == msk_y.shape, 'Data have different shapes'\n",
    "        assert img_X1.shape[1] <= max_size[0] and img_X1.shape[2] <= max_size[1], 'Data have too large shape'\n",
    "        assert X1_res == X2_res and X1_res == y_res, 'Data resolutions are different'\n",
    "        assert np.isclose(X1_res[0], X1_res[1]), 'Data resolution is not consistent for x and y axis'\n",
    "        assert np.isclose(X1_res[0], target_resolution), 'Rescaling not supported yet'\n",
    "        assert img_X1.shape[0] == 5, 'Only 5 timeslices accepted'\n",
    "        assert np.all(np.unique(msk_y) == [0,1]) or np.all(np.unique(msk_y) == [0]), 'Mask is not binary'\n",
    "        \n",
    "        img_X1 = np.pad(\n",
    "            img_X1,\n",
    "            pad_width=((0, 0), (0, max_size[0] - img_X1.shape[1]), (0, max_size[1] - img_X1.shape[2])),\n",
    "            mode='constant',\n",
    "            constant_values=0\n",
    "        )\n",
    "        img_X2 = np.pad(\n",
    "            img_X2,\n",
    "            pad_width=((0, 0), (0, max_size[0] - img_X2.shape[1]), (0, max_size[1] - img_X2.shape[2])),\n",
    "            mode='constant',\n",
    "            constant_values=0\n",
    "        )\n",
    "        msk_y = np.pad(\n",
    "            msk_y,\n",
    "            pad_width=((0, 0), (0, max_size[0] - msk_y.shape[1]), (0, max_size[1] - msk_y.shape[2])),\n",
    "            mode='constant',\n",
    "            constant_values=0\n",
    "        )\n",
    "\n",
    "        img_X1 = img_X1.astype(np.float32)\n",
    "        img_X2 = img_X2.astype(np.float32)\n",
    "        msk_y = msk_y.astype(np.uint8)\n",
    "        \n",
    "        img_X1 = img_X1 - min_vals['X1']\n",
    "        img_X2 = img_X2 - min_vals['X2']\n",
    "        \n",
    "        img_X1[img_X1 < effective_ranges['X1'][0]] = effective_ranges['X1'][0]\n",
    "        img_X1[img_X1 > effective_ranges['X1'][1]] = effective_ranges['X1'][1]\n",
    "        img_X2[img_X2 < effective_ranges['X2'][0]] = effective_ranges['X2'][0]\n",
    "        img_X2[img_X2 > effective_ranges['X2'][1]] = effective_ranges['X2'][1]\n",
    "        \n",
    "        img_X1 = img_X1 / effective_ranges['X1'][1]\n",
    "        img_X2 = img_X2 / effective_ranges['X2'][1]\n",
    "        \n",
    "        img_X1 = np.expand_dims(img_X1, axis=-1)\n",
    "        img_X2 = np.expand_dims(img_X2, axis=-1)\n",
    "        msk_y = np.expand_dims(msk_y, axis=-1)\n",
    "\n",
    "        X1.append(img_X1)\n",
    "        X2.append(img_X2)        \n",
    "        y.append(msk_y)        \n",
    "    \n",
    "    return np.array(X1), np.array(X2), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ed7d2",
   "metadata": {},
   "source": [
    "Call the function and load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40649b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2, y = load_image_and_masks(img_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a148ca",
   "metadata": {},
   "source": [
    "Randomly split to train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(np.arange(len(X1)))\n",
    "split_idx = len(X1) - round(len(X1) * validation_fraction)\n",
    "train_indices = perm[:split_idx]\n",
    "val_indices = perm[split_idx:]\n",
    "\n",
    "X1_train, X2_train, y_train = [], [], []\n",
    "for i in train_indices:\n",
    "    X1_train.extend(X1[i])\n",
    "    X2_train.extend(X2[i])\n",
    "    y_train.extend(y[i])\n",
    "\n",
    "X1_val, X2_val, y_val = [], [], []\n",
    "for i in val_indices:\n",
    "    X1_val.extend(X1[i])\n",
    "    X2_val.extend(X2[i])\n",
    "    y_val.extend(y[i])\n",
    "\n",
    "X1_train = np.array(X1_train, dtype=np.float32)\n",
    "X2_train = np.array(X2_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.uint8)\n",
    "X1_val = np.array(X1_val, dtype=np.float32)\n",
    "X2_val = np.array(X2_val, dtype=np.float32)\n",
    "y_val = np.array(y_val, dtype=np.uint8)\n",
    "\n",
    "print(X1_train.shape, X1_val.shape)\n",
    "print(X2_train.shape, X2_val.shape)\n",
    "print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade73695",
   "metadata": {},
   "source": [
    "Plot example of training data with flou, aflou, and mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19488ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 5, figsize=(60, 20))\n",
    "random_img_idx = 42\n",
    "\n",
    "for slice_i, ax in enumerate(zip(*axes)):\n",
    "    \n",
    "    ax[0].imshow(X1_train[random_img_idx + slice_i, ..., 0], cmap='hot')\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    ax[1].imshow(X2_train[random_img_idx + slice_i, ..., 0], cmap='hot')\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    ax[2].imshow(y_train[random_img_idx + slice_i, ..., 0], cmap='hot')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377cb71",
   "metadata": {},
   "source": [
    "Save data to file for loading in training notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347cf6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('data/compiled_vessel_seg_data_final.h5', 'w')\n",
    "#h5f = h5py.File('data/compiled_punctae_seg_data_final.h5', 'w')\n",
    "h5f.create_dataset('X1_train', data=X1_train)\n",
    "h5f.create_dataset('X1_val', data=X1_val)\n",
    "h5f.create_dataset('X2_train', data=X2_train)\n",
    "h5f.create_dataset('X2_val', data=X2_val)\n",
    "h5f.create_dataset('y_train', data=y_train)\n",
    "h5f.create_dataset('y_val', data=y_val)\n",
    "h5f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
