{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4eb0b21",
   "metadata": {},
   "source": [
    "# Train U-net for punctae segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b5404",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402556ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "from os import walk, makedirs\n",
    "from os.path import join, exists\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "import segmentation_models as sm\n",
    "from tqdm import tqdm\n",
    "from segmentation_models.metrics import f1_score, iou_score\n",
    "from skimage import filters\n",
    "import glob\n",
    "import re\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.set_framework('tf.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010a19f",
   "metadata": {},
   "source": [
    "Set training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 200\n",
    "model_name = 'punctae_seg_model'\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b9373",
   "metadata": {},
   "source": [
    "## Loading image and masks\n",
    "Load pre-compiled image data and the punctae dot masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File('data/compiled_punctae_seg_data_final.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = data['X_train'], data['X_val'], data['y_train'], data['y_val']\n",
    "print(X_train.shape, X_train.dtype)\n",
    "print(X_val.shape, X_val.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(y_val.shape, y_val.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229216f5",
   "metadata": {},
   "source": [
    "## Capability for restarting training.\n",
    "Load previous weights if they exist or start from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333431e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = None\n",
    "start_from_epoch = 0\n",
    "if not exists(model_name):\n",
    "    print('Training from scratch.')\n",
    "    makedirs(model_name)\n",
    "else:\n",
    "    models = glob.glob(join(model_name, '*.h5'))\n",
    "    if len(models) == 0:\n",
    "        print('No models were stored. Training from scratch.')\n",
    "    else:\n",
    "        model_weights_path = max(glob.glob(join(model_name, '*.h5')), key=lambda x: int(re.findall('\\.(\\d{3})-', x)[0]))\n",
    "        start_from_epoch = int(re.findall('\\.(\\d{3})-', model_weights_path)[0])\n",
    "        print('Starting from checkpoint %s. Epoch=%i (one-indexed)' % (model_weights_path, start_from_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1f5b7",
   "metadata": {},
   "source": [
    "## Definition of the U-net model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86284a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet( \n",
    "    'resnet34',\n",
    "    classes=1,\n",
    "    activation='sigmoid',\n",
    "    encoder_weights='imagenet',\n",
    "    input_shape=(X_train.shape[1:-1]) + (3,),\n",
    "    decoder_block_type='transpose'\n",
    ")\n",
    "\n",
    "image_input = tf.keras.Input(shape=(X_train.shape[1:-1]) + (2,), dtype=tf.float32, name='image_input')\n",
    "image_repeat = tf.keras.layers.Conv2D(filters=3, kernel_size=(3,3), padding='same')(image_input)\n",
    "\n",
    "posterior = model(image_repeat)\n",
    "\n",
    "model = tf.keras.Model(inputs=image_input, outputs=posterior)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d405ed5",
   "metadata": {},
   "source": [
    "## Compile model with DICE loss\n",
    "Define soft DICE loss and DICE for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c37dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dice(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = tf.cast(tf.where(y_true > 0.01, 1, 0), tf.float32)\n",
    "    y_pred_f = tf.cast(tf.where(y_pred > 0.01, 1, 0), tf.float32)\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_f)\n",
    "    y_pred_f = K.flatten(y_pred_f)\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    \n",
    "    dice = (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "    return dice\n",
    "\n",
    "def my_dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2.0 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1-dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476220c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "    loss=my_dice_loss,\n",
    "    metrics=[my_dice]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a2792",
   "metadata": {},
   "source": [
    "Load the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_weights_path is not None:\n",
    "    print('Loading weights %s' % model_weights_path)\n",
    "    model.load_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24410344",
   "metadata": {},
   "source": [
    "## Create online augmentation object for image-mask pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2553017",
   "metadata": {},
   "source": [
    "Augmentation for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db2208",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args_img = dict(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    shear_range=15,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    zoom_range=[0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function = lambda x: x,\n",
    ")\n",
    "\n",
    "data_gen_args_msk = dict(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    shear_range=15,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    zoom_range=[0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    "    # Mask dtype becomes float. Need to cast to int again.\n",
    "    preprocessing_function = lambda x: np.where(x > filters.threshold_otsu(x), 1, 0) if not np.all(x == 0) else np.where(x > 0, 1, 0),\n",
    ")\n",
    "\n",
    "image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args_img) \n",
    "mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args_msk)\n",
    "\n",
    "image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "train_image_generator = image_datagen.flow(X_train, batch_size=batch_size, seed=seed, shuffle=True)\n",
    "train_mask_generator = mask_datagen.flow(y_train, batch_size=batch_size, seed=seed, shuffle=True)\n",
    "\n",
    "train_generator = zip(train_image_generator, train_mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7769137b",
   "metadata": {},
   "source": [
    "Create the same object for validation set, however without augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59507395",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args_img_val = dict(\n",
    "    rotation_range=0,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    shear_range=0,\n",
    "    brightness_range=[1.0, 1.0],\n",
    "    zoom_range=[1.0, 1.0],\n",
    "    fill_mode='reflect',\n",
    "    preprocessing_function = lambda x: x,\n",
    ")\n",
    "\n",
    "data_gen_args_msk_val = dict(\n",
    "    rotation_range=0,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    shear_range=0,\n",
    "    brightness_range=[1.0, 1.0],\n",
    "    zoom_range=[1.0, 1.0],\n",
    "    fill_mode='nearest',\n",
    "    # Mask dtype becomes float. Need to cast to int again.\n",
    "    preprocessing_function = lambda x: np.where(x > filters.threshold_otsu(x), 1, 0) if not np.all(x == 0) else np.where(x > 0, 1, 0),\n",
    ")\n",
    "\n",
    "val_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args_img_val)\n",
    "val_mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args_msk_val)\n",
    "\n",
    "val_image_datagen.fit(X_val, augment=False, seed=seed)\n",
    "val_mask_datagen.fit(y_val, augment=False, seed=seed)\n",
    "\n",
    "val_image_generator = val_image_datagen.flow(X_val, batch_size=batch_size, seed=seed, shuffle=False)\n",
    "val_mask_generator = val_mask_datagen.flow(y_val, batch_size=batch_size, seed=seed, shuffle=False)\n",
    "\n",
    "validation_generator = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0731103a",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e3908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = np.ceil(len(X_train) / batch_size),\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps= np.ceil(len(X_val) / batch_size),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=join(model_name, 'model.{epoch:03d}-{val_my_dice:.4f}.h5'))\n",
    "    ],\n",
    "    initial_epoch=start_from_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8d4a0",
   "metadata": {},
   "source": [
    "Make sure to save training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"punctae_training_history.pkl\", \"wb\")\n",
    "pickle.dump(history.history, a_file)\n",
    "a_file.close()\n",
    "training_history = history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da06fc6a",
   "metadata": {},
   "source": [
    "Store training history (DICE) to pdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95968834",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(len(training_history['loss']))\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "plt.plot(epochs, training_history['my_dice'], label='Training')\n",
    "plt.plot(epochs, training_history['val_my_dice'], label='Validation')\n",
    "\n",
    "plt.ylabel('DICE', fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.rc('ytick', labelsize=15)\n",
    "plt.xlim((0, 200))\n",
    "plt.ylim((0, 1.0))\n",
    "plt.grid()\n",
    "plt.legend(loc=4, prop={'size': 20})\n",
    "plt.savefig('convergence_punctae.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
